{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Project Overview\n",
        "\n",
        "This project aims to predict an NBA player's points, rebounds and assists scored in a game\n",
        "based on historical game statistics.\n",
        "It is a Supervised Learning problem (Regression task).\n",
        "We will explore results using Linear Regression models, Ridge Regression,\n",
        "Random Forest Regression, and Kernel Density Estimation\n",
        "to analyze player performance.\n",
        "\n",
        "This model can be used for Sportsbetting, as you can see what betting lines have value relative to their\n",
        "chance of hitting."
      ],
      "metadata": {
        "id": "aynUzJhGSFtF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "from google.colab import drive\n",
        "from scipy.stats import norm\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display\n",
        "from sklearn.linear_model import Ridge\n",
        "from scipy.stats import gaussian_kde\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "mzYsmDPSGR_i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Source\n",
        "\n",
        "This project uses publicly available data found at https://www.kaggle.com/datasets/eoinamoore/historical-nba-data-and-player-box-scores?resource=download by Eoin A Moore\n",
        "\n",
        "This dataset consists of tabular data in several files such as TeamStatistics, PlayerStatistics, Games and LeagueSchedule, collectively being 97 MB in size.\n",
        "\n",
        "These files conosist of numerical data such as points and rebounds, as well of categorical data like firstName, lastName, teamName, gameType, etc.\n"
      ],
      "metadata": {
        "id": "cs2RPh3uWQzY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Cleaning\n",
        "\n",
        "We begin by cleaning the dataset to ensure that it is suitable for analysis. For this project, only Player Statistics was used.Some key steps include:\n",
        "\n",
        "1. **Handling missing values**: If there are any NaN or null values in the dataset, we will either impute them with the mean/median or drop rows with missing values.\n",
        "2. **Feature selection**: We select only the most relevant features (e.g., points, rebounds, assists)\n",
        "3. **Removing outliers**: We filter out extreme outliers for the specific stats as well as minutes played.\n",
        "\n",
        "The following visualizations highlight the distribution of these features and check for any missing data or outliers."
      ],
      "metadata": {
        "id": "GwIj3ntFSNWD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')\n",
        "folder_path = '/content/drive/MyDrive/NBADatabase/'\n",
        "\n",
        "player_stats = pd.read_csv(folder_path + 'PlayerStatistics.csv')\n",
        "\n",
        "selected_columns = [\n",
        "    'firstName', 'lastName', 'numMinutes', 'assists', 'blocks', 'steals',\n",
        "    'fieldGoalsPercentage', 'threePointersPercentage', 'freeThrowsPercentage',\n",
        "    'fieldGoalsAttempted', 'threePointersAttempted', 'freeThrowsAttempted',\n",
        "    'reboundsDefensive', 'reboundsOffensive', 'reboundsTotal', 'turnovers', 'plusMinusPoints',\n",
        "    'opponentteamName', 'playerteamName', 'gameType', 'home', 'gameDate',\n",
        "    'points'\n",
        "]\n",
        "\n",
        "player_stats = player_stats[selected_columns]\n",
        "\n",
        "player_stats = player_stats.dropna(subset=['numMinutes', 'fieldGoalsPercentage', 'points'])\n",
        "\n",
        "player_stats.head()"
      ],
      "metadata": {
        "id": "FzTdZR8EnTSA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following is some exploratory data analysis including histograms and boxplots. As you can see by plotting points, rebounds, and assists against opponent team, certain opponent teams allow for more stats than others. This is over the course of decades, but the players we will test for will be tested with the data of their era."
      ],
      "metadata": {
        "id": "J1UkSkxYaF_9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "features = ['points', 'reboundsTotal', 'assists']\n",
        "\n",
        "# Plotting histograms for each feature\n",
        "for feature in features:\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.histplot(player_stats[feature], kde=True, color='blue')\n",
        "    plt.title(f'Distribution of {feature}')\n",
        "    plt.xlabel(feature)\n",
        "    plt.ylabel('Frequency')\n",
        "    plt.show()\n",
        "\n",
        "# Plotting box plots for each feature to check for outliers\n",
        "for feature in features:\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.boxplot(x=player_stats[feature], color='orange')\n",
        "    plt.title(f'Box Plot of {feature}')\n",
        "    plt.xlabel(feature)\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "corr_matrix = player_stats[['points', 'reboundsTotal', 'assists']].corr()\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt=\".2f\", linewidths=0.5)\n",
        "plt.title(\"Correlation Matrix of Points, Rebounds, and Assists\")\n",
        "plt.show()\n",
        "\n",
        "opponent_stats = player_stats.groupby('opponentteamName')[['points', 'reboundsTotal', 'assists']].mean()\n",
        "\n",
        "# Visualizing the performance against different opponents\n",
        "opponent_stats.plot(kind='bar', figsize=(12, 8))\n",
        "plt.title('Average Performance (Points, Rebounds, Assists) Against Each Opponent')\n",
        "plt.ylabel('Average Stats')\n",
        "plt.xlabel('Opponent Team')\n",
        "plt.xticks(rotation=90)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "D_RficqAaHu3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is the initial linear regression model that can be used for points, rebounds or assists.\n",
        "It uses the players's last 20 overall games as well as the player's last 10 games against\n",
        "the specific opponent. A trendline is created based on those games to determine a prediction for the next game.\n",
        "Based on those 30 games, a standard deviation is created and used to build a normal distribution around that\n",
        "prediction to see confidence levels for other point/rebound/assist totals.\n",
        "A gameNumber feature is created to track the games.\n",
        "'''"
      ],
      "metadata": {
        "id": "S9a8q1kwSXTD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Linear Regression\n",
        "def drop_highest_and_lowest(df, column='points'):\n",
        "    if len(df) <= 2:\n",
        "        return df\n",
        "    idx_max = df[column].idxmax()\n",
        "    idx_min = df[column].idxmin()\n",
        "    df = df.drop([idx_max, idx_min])\n",
        "    return df\n",
        "\n",
        "def predict_stat_distribution(stat_name, first_name, last_name, opponent_team, is_home_game):\n",
        "    if not np.issubdtype(player_stats['gameDate'].dtype, np.datetime64):\n",
        "        player_stats['gameDate'] = pd.to_datetime(player_stats['gameDate'])\n",
        "    filtered_stats = player_stats[player_stats['numMinutes'] >= 10]\n",
        "    all_games = filtered_stats[\n",
        "        (filtered_stats['firstName'] == first_name) &\n",
        "        (filtered_stats['lastName'] == last_name)\n",
        "    ].sort_values('gameDate')\n",
        "    opponent_games = all_games[all_games['opponentteamName'] == opponent_team]\n",
        "\n",
        "    if all_games.empty or opponent_games.empty:\n",
        "        print(f\"No sufficient data for {first_name} {last_name} vs {opponent_team}.\")\n",
        "        return None, None\n",
        "\n",
        "    recent_games = all_games[all_games['home'] == is_home_game].tail(20)\n",
        "    recent_opponent_games = opponent_games[opponent_games['home'] == is_home_game].tail(10)\n",
        "\n",
        "    if recent_games.empty or recent_opponent_games.empty:\n",
        "        print(f\"No recent or matchup games found.\")\n",
        "        return None, None\n",
        "\n",
        "    recent_games = drop_highest_and_lowest(recent_games, column=stat_name)\n",
        "    recent_opponent_games = drop_highest_and_lowest(recent_opponent_games, column=stat_name)\n",
        "\n",
        "    print(f\"\\n Recent Form Games for {stat_name.capitalize()}:\")\n",
        "    display(recent_games[['gameDate', 'opponentteamName', stat_name, 'numMinutes', 'home']])\n",
        "    print(f\"\\n Matchup Games for {stat_name.capitalize()}:\")\n",
        "    display(recent_opponent_games[['gameDate', 'opponentteamName', stat_name, 'numMinutes', 'home']])\n",
        "\n",
        "    recent_games = recent_games.reset_index(drop=True)\n",
        "    recent_games['gameNumber'] = np.arange(len(recent_games))\n",
        "    X_recent = recent_games['gameNumber'].values.reshape(-1,1)\n",
        "    y_recent = recent_games[stat_name].values\n",
        "    model_recent = LinearRegression()\n",
        "    model_recent.fit(X_recent, y_recent)\n",
        "\n",
        "    recent_opponent_games = recent_opponent_games.reset_index(drop=True)\n",
        "    recent_opponent_games['gameNumber'] = np.arange(len(recent_opponent_games))\n",
        "    X_opponent = recent_opponent_games['gameNumber'].values.reshape(-1,1)\n",
        "    y_opponent = recent_opponent_games[stat_name].values\n",
        "    model_opponent = LinearRegression()\n",
        "    model_opponent.fit(X_opponent, y_opponent)\n",
        "\n",
        "    pred_recent = model_recent.predict(np.array([[len(recent_games)]]))[0]\n",
        "    pred_opponent = model_opponent.predict(np.array([[len(recent_opponent_games)]]))[0]\n",
        "    final_pred = 0.6 * pred_recent + 0.4 * pred_opponent\n",
        "\n",
        "    r2_recent = model_recent.score(X_recent, y_recent)\n",
        "    r2_opponent = model_opponent.score(X_opponent, y_opponent)\n",
        "    avg_r2 = (r2_recent + r2_opponent) / 2\n",
        "    base_std_dev = np.std(np.concatenate([y_recent, y_opponent]))\n",
        "    adj_std_dev = base_std_dev * (1 - avg_r2)\n",
        "    adj_std_dev = max(adj_std_dev, 1)\n",
        "\n",
        "    x = np.linspace(final_pred - 3*adj_std_dev, final_pred + 3*adj_std_dev, 500)\n",
        "    y = norm.pdf(x, final_pred, adj_std_dev)\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(8,6))\n",
        "    ax.plot(x, y)\n",
        "    ax.fill_between(x, y, alpha=0.5)\n",
        "    ax.axvline(final_pred, color='red', linestyle='--', label=f'Predicted {stat_name}: {final_pred:.2f}')\n",
        "\n",
        "    thresholds = []\n",
        "    if final_pred <= 10:\n",
        "        thresholds = [int(final_pred - 4), int(final_pred - 2), int(final_pred), int(final_pred + 2), int(final_pred + 4)]\n",
        "    elif final_pred <= 20:\n",
        "        thresholds = [int(final_pred - 6), int(final_pred - 3), int(final_pred), int(final_pred + 3), int(final_pred + 6)]\n",
        "    else:\n",
        "        thresholds = [int(final_pred - 10), int(final_pred - 5), int(final_pred), int(final_pred + 5), int(final_pred + 10)]\n",
        "    thresholds = [thresh for thresh in thresholds if thresh > 0]\n",
        "\n",
        "    for thresh in thresholds:\n",
        "        y_thresh = norm.pdf(thresh, final_pred, adj_std_dev)\n",
        "        prob = (1 - norm.cdf(thresh, final_pred, adj_std_dev)) * 100\n",
        "        ax.scatter(thresh, y_thresh, color='black')\n",
        "        ax.text(thresh, y_thresh + max(y)*0.03, f'{thresh} ({prob:.0f}%)',\n",
        "                ha='center', fontsize=9, color='black')\n",
        "\n",
        "    ax.set_title(f'Predicted {stat_name.capitalize()} Distribution')\n",
        "    ax.set_xlabel(f'{stat_name.capitalize()}')\n",
        "    ax.set_ylabel('Probability Density')\n",
        "    ax.legend()\n",
        "    plt.show()\n",
        "\n",
        "    print(f\"\\n Interactive Probability Slider for {stat_name.capitalize()}:\")\n",
        "    slider = widgets.IntSlider(\n",
        "        value=int(final_pred),\n",
        "        min=int(final_pred - 10),\n",
        "        max=int(final_pred + 20),\n",
        "        step=1,\n",
        "        description=f'{stat_name}',\n",
        "        continuous_update=False\n",
        "    )\n",
        "    def calculate_probability(threshold):\n",
        "        prob = 1 - norm.cdf(threshold, final_pred, adj_std_dev)\n",
        "        print(f\" Probability of more than {threshold} {stat_name}: {prob*100:.2f}%\")\n",
        "    output = widgets.interactive_output(calculate_probability, {'threshold': slider})\n",
        "    display(slider, output)\n",
        "\n",
        "    return final_pred, adj_std_dev\n",
        "\n",
        "def player_full_report(first_name, last_name, opponent_team, is_home_game):\n",
        "    print(f\"\\n=== {first_name} {last_name} vs {opponent_team} ({'Home' if is_home_game else 'Away'}) ===\\n\")\n",
        "\n",
        "    print(\"\\n POINTS Prediction:\")\n",
        "    points_pred, points_std = predict_stat_distribution('points', first_name, last_name, opponent_team, is_home_game)\n",
        "\n",
        "    print(\"\\n REBOUNDS Prediction:\")\n",
        "    rebounds_pred, rebounds_std = predict_stat_distribution('reboundsTotal', first_name, last_name, opponent_team, is_home_game)\n",
        "\n",
        "    print(\"\\n ASSISTS Prediction:\")\n",
        "    assists_pred, assists_std = predict_stat_distribution('assists', first_name, last_name, opponent_team, is_home_game)\n",
        "\n",
        "    print(\"\\n📋 SUMMARY REPORT:\")\n",
        "    summary_data = {\n",
        "        'Stat': ['Points', 'Rebounds', 'Assists'],\n",
        "        'Predicted Value': [\n",
        "            f'{points_pred:.2f}' if points_pred else 'N/A',\n",
        "            f'{rebounds_pred:.2f}' if rebounds_pred else 'N/A',\n",
        "            f'{assists_pred:.2f}' if assists_pred else 'N/A'\n",
        "        ]\n",
        "    }\n",
        "    summary_df = pd.DataFrame(summary_data)\n",
        "    display(summary_df)\n",
        "    print(\"\\n Full Player Report Complete!\")\n",
        "\n",
        "\n",
        "player_full_report('Stephen', 'Curry', 'Rockets', is_home_game=1)\n",
        "\n"
      ],
      "metadata": {
        "id": "cB_uSbcHMzH8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is a simulated comparison between different models.\n",
        "Conclusion: Random Forest Regression is much more accurate than Linear Regression over time."
      ],
      "metadata": {
        "id": "97m0EFc3SeBz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Ridge Regression, Random Forest, and Linear Regression Comparison\n",
        "def prepare_recent_data(first_name, last_name, is_home_game):\n",
        "    filtered_stats = player_stats[player_stats['numMinutes'] >= 10]\n",
        "    if not np.issubdtype(player_stats['gameDate'].dtype, np.datetime64):\n",
        "        player_stats['gameDate'] = pd.to_datetime(player_stats['gameDate'])\n",
        "\n",
        "    all_games = filtered_stats[\n",
        "        (filtered_stats['firstName'] == first_name) &\n",
        "        (filtered_stats['lastName'] == last_name) &\n",
        "        (filtered_stats['home'] == is_home_game)\n",
        "    ].sort_values('gameDate')\n",
        "\n",
        "    all_games = all_games.tail(20)\n",
        "    all_games = drop_highest_and_lowest(all_games, column='points')\n",
        "\n",
        "    all_games = all_games.reset_index(drop=True)\n",
        "    all_games['gameNumber'] = np.arange(len(all_games))\n",
        "\n",
        "    X = all_games[['gameNumber']]\n",
        "    y = all_games['points']\n",
        "\n",
        "    return X, y\n",
        "\n",
        "def train_and_compare_models(first_name, last_name, is_home_game=1):\n",
        "    X, y = prepare_recent_data(first_name, last_name, is_home_game)\n",
        "\n",
        "    # Linear Regression\n",
        "    lin_model = LinearRegression()\n",
        "    lin_model.fit(X, y)\n",
        "    lin_preds = lin_model.predict(X)\n",
        "\n",
        "    # Ridge Regression\n",
        "    ridge_model = Ridge(alpha=1.0)\n",
        "    ridge_model.fit(X, y)\n",
        "    ridge_preds = ridge_model.predict(X)\n",
        "\n",
        "    # Random Forest Regressor with hyperparameter tuning\n",
        "    rf_model = RandomForestRegressor(random_state=42)\n",
        "    param_grid = {'max_depth': [3, 5, 7, 10, None]}\n",
        "    grid_search = GridSearchCV(rf_model, param_grid, cv=3, scoring='neg_mean_absolute_error')\n",
        "    grid_search.fit(X, y)\n",
        "    best_rf_model = grid_search.best_estimator_\n",
        "    rf_preds = best_rf_model.predict(X)\n",
        "\n",
        "    #Evaluate\n",
        "    models = {\n",
        "        'Linear Regression': lin_preds,\n",
        "        'Ridge Regression': ridge_preds,\n",
        "        'Random Forest Regressor': rf_preds\n",
        "    }\n",
        "\n",
        "    print(\"\\n Model Comparison Metrics\\n\")\n",
        "    results = []\n",
        "    for name, preds in models.items():\n",
        "        mae = mean_absolute_error(y, preds)\n",
        "        rmse = mean_squared_error(y, preds) ** 0.5\n",
        "        results.append((name, mae, rmse))\n",
        "        print(f\"{name}: MAE = {mae:.2f}, RMSE = {rmse:.2f}\")\n",
        "\n",
        "    results_df = pd.DataFrame(results, columns=['Model', 'MAE', 'RMSE'])\n",
        "    display(results_df)\n",
        "\n",
        "    print(\"\\n Best Random Forest Parameters:\")\n",
        "    print(grid_search.best_params_)\n",
        "\n",
        "train_and_compare_models('Stephen', 'Curry', is_home_game=1)"
      ],
      "metadata": {
        "id": "wsNjDTHDMzKs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is the player prediction model using Random Forest Regression.\n",
        "It still uses the players's last 20 overall games as well as the player's last 10 games against\n",
        "the specific opponent. A trendline is created based on those games to determine a prediction for the next game.\n",
        "Conclusion: While the center is more accurate, the spread of the model isn't very realistic.\n",
        "In the example, Stephen Curry vs the Rockets,\n",
        "it simply isnt realistic that there is a 100% chance of him scoring 27 or more points."
      ],
      "metadata": {
        "id": "XH5ypRWVSgmc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Random Forest Player Prediction\n",
        "\n",
        "# Helper: Drop highest and lowest scoring games\n",
        "def drop_highest_and_lowest(df, column='points'):\n",
        "    if len(df) <= 2:\n",
        "        return df\n",
        "    idx_max = df[column].idxmax()\n",
        "    idx_min = df[column].idxmin()\n",
        "    df = df.drop([idx_max, idx_min])\n",
        "    return df\n",
        "\n",
        "# Main Predict Function (Random Forest version)\n",
        "def predict_stat_distribution(stat_name, first_name, last_name, opponent_team, is_home_game):\n",
        "    if not np.issubdtype(player_stats['gameDate'].dtype, np.datetime64):\n",
        "        player_stats['gameDate'] = pd.to_datetime(player_stats['gameDate'])\n",
        "    filtered_stats = player_stats[player_stats['numMinutes'] >= 10]\n",
        "    all_games = filtered_stats[\n",
        "        (filtered_stats['firstName'] == first_name) &\n",
        "        (filtered_stats['lastName'] == last_name)\n",
        "    ].sort_values('gameDate')\n",
        "    opponent_games = all_games[all_games['opponentteamName'] == opponent_team]\n",
        "\n",
        "    if all_games.empty or opponent_games.empty:\n",
        "        print(f\" No sufficient data for {first_name} {last_name} vs {opponent_team}.\")\n",
        "        return None, None\n",
        "\n",
        "    recent_games = all_games[all_games['home'] == is_home_game].tail(20)\n",
        "    recent_opponent_games = opponent_games[opponent_games['home'] == is_home_game].tail(10)\n",
        "\n",
        "    if recent_games.empty or recent_opponent_games.empty:\n",
        "        print(f\" No recent or matchup games found.\")\n",
        "        return None, None\n",
        "\n",
        "    recent_games = drop_highest_and_lowest(recent_games, column=stat_name)\n",
        "    recent_opponent_games = drop_highest_and_lowest(recent_opponent_games, column=stat_name)\n",
        "\n",
        "    print(f\"\\n Recent Form Games for {stat_name.capitalize()}:\")\n",
        "    display(recent_games[['gameDate', 'opponentteamName', stat_name, 'numMinutes', 'home']])\n",
        "    print(f\"\\n Matchup Games for {stat_name.capitalize()}:\")\n",
        "    display(recent_opponent_games[['gameDate', 'opponentteamName', stat_name, 'numMinutes', 'home']])\n",
        "\n",
        "    recent_games = recent_games.reset_index(drop=True)\n",
        "    recent_games['gameNumber'] = np.arange(len(recent_games))\n",
        "    X_recent = recent_games[['gameNumber']]\n",
        "    y_recent = recent_games[stat_name]\n",
        "\n",
        "    recent_opponent_games = recent_opponent_games.reset_index(drop=True)\n",
        "    recent_opponent_games['gameNumber'] = np.arange(len(recent_opponent_games))\n",
        "    X_opponent = recent_opponent_games[['gameNumber']]\n",
        "    y_opponent = recent_opponent_games[stat_name]\n",
        "\n",
        "    # Model Recent Games (Random Forest)\n",
        "    model_recent = RandomForestRegressor(max_depth=3, random_state=42)\n",
        "    model_recent.fit(X_recent, y_recent)\n",
        "\n",
        "    # Model Opponent Games (Random Forest)\n",
        "    model_opponent = RandomForestRegressor(max_depth=3, random_state=42)\n",
        "    model_opponent.fit(X_opponent, y_opponent)\n",
        "\n",
        "    # Predictions\n",
        "    pred_recent = model_recent.predict(np.array([[len(recent_games)]]))[0]\n",
        "    pred_opponent = model_opponent.predict(np.array([[len(recent_opponent_games)]]))[0]\n",
        "    final_pred = 0.6 * pred_recent + 0.4 * pred_opponent\n",
        "\n",
        "    # Spread estimation (pseudo R2 approach)\n",
        "    y_recent_pred = model_recent.predict(X_recent)\n",
        "    y_opponent_pred = model_opponent.predict(X_opponent)\n",
        "\n",
        "    ss_recent_res = np.sum((y_recent - y_recent_pred)**2)\n",
        "    ss_recent_tot = np.sum((y_recent - np.mean(y_recent))**2)\n",
        "    r2_recent = 1 - ss_recent_res/ss_recent_tot\n",
        "\n",
        "    ss_opponent_res = np.sum((y_opponent - y_opponent_pred)**2)\n",
        "    ss_opponent_tot = np.sum((y_opponent - np.mean(y_opponent))**2)\n",
        "    r2_opponent = 1 - ss_opponent_res/ss_opponent_tot\n",
        "\n",
        "    avg_r2 = (r2_recent + r2_opponent) / 2\n",
        "    base_std_dev = np.std(np.concatenate([y_recent, y_opponent]))\n",
        "    adj_std_dev = base_std_dev * (1 - avg_r2)\n",
        "    adj_std_dev = max(adj_std_dev, 1)\n",
        "\n",
        "    #Bell curve plotting\n",
        "    x = np.linspace(final_pred - 3*adj_std_dev, final_pred + 3*adj_std_dev, 500)\n",
        "    y = norm.pdf(x, final_pred, adj_std_dev)\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(8,6))\n",
        "    ax.plot(x, y)\n",
        "    ax.fill_between(x, y, alpha=0.5)\n",
        "    ax.axvline(final_pred, color='red', linestyle='--', label=f'Predicted {stat_name}: {final_pred:.2f}')\n",
        "\n",
        "    thresholds = []\n",
        "    if final_pred <= 10:\n",
        "        thresholds = [int(final_pred - 4), int(final_pred - 2), int(final_pred), int(final_pred + 2), int(final_pred + 4)]\n",
        "    elif final_pred <= 20:\n",
        "        thresholds = [int(final_pred - 6), int(final_pred - 3), int(final_pred), int(final_pred + 3), int(final_pred + 6)]\n",
        "    else:\n",
        "        thresholds = [int(final_pred - 10), int(final_pred - 5), int(final_pred), int(final_pred + 5), int(final_pred + 10)]\n",
        "    thresholds = [thresh for thresh in thresholds if thresh > 0]\n",
        "\n",
        "    for thresh in thresholds:\n",
        "        y_thresh = norm.pdf(thresh, final_pred, adj_std_dev)\n",
        "        prob = (1 - norm.cdf(thresh, final_pred, adj_std_dev)) * 100\n",
        "        ax.scatter(thresh, y_thresh, color='black')\n",
        "        ax.text(thresh, y_thresh + max(y)*0.03, f'{thresh} ({prob:.0f}%)',\n",
        "                ha='center', fontsize=9, color='black')\n",
        "\n",
        "    ax.set_title(f'Predicted {stat_name.capitalize()} Distribution (Random Forest)')\n",
        "    ax.set_xlabel(f'{stat_name.capitalize()}')\n",
        "    ax.set_ylabel('Probability Density')\n",
        "    ax.legend()\n",
        "    plt.show()\n",
        "\n",
        "    print(f\"\\n Interactive Probability Slider for {stat_name.capitalize()}:\")\n",
        "    slider = widgets.IntSlider(\n",
        "        value=int(final_pred),\n",
        "        min=int(final_pred - 10),\n",
        "        max=int(final_pred + 20),\n",
        "        step=1,\n",
        "        description=f'{stat_name}',\n",
        "        continuous_update=False\n",
        "    )\n",
        "    def calculate_probability(threshold):\n",
        "        prob = 1 - norm.cdf(threshold, final_pred, adj_std_dev)\n",
        "        print(f\" Probability of more than {threshold} {stat_name}: {prob*100:.2f}%\")\n",
        "    output = widgets.interactive_output(calculate_probability, {'threshold': slider})\n",
        "    display(slider, output)\n",
        "\n",
        "    return final_pred, adj_std_dev\n",
        "\n",
        "# Full Player Report (Calls predict_stat_distribution for Points, Rebounds, Assists)\n",
        "def player_full_report(first_name, last_name, opponent_team, is_home_game):\n",
        "    print(f\"\\n=== {first_name} {last_name} vs {opponent_team} ({'Home' if is_home_game else 'Away'}) ===\\n\")\n",
        "\n",
        "    print(\"\\n POINTS Prediction:\")\n",
        "    points_pred, points_std = predict_stat_distribution('points', first_name, last_name, opponent_team, is_home_game)\n",
        "\n",
        "    print(\"\\n REBOUNDS Prediction:\")\n",
        "    rebounds_pred, rebounds_std = predict_stat_distribution('reboundsTotal', first_name, last_name, opponent_team, is_home_game)\n",
        "\n",
        "    print(\"\\n ASSISTS Prediction:\")\n",
        "    assists_pred, assists_std = predict_stat_distribution('assists', first_name, last_name, opponent_team, is_home_game)\n",
        "\n",
        "    print(\"\\n SUMMARY REPORT:\")\n",
        "    summary_data = {\n",
        "        'Stat': ['Points', 'Rebounds', 'Assists'],\n",
        "        'Predicted Value': [\n",
        "            f'{points_pred:.2f}' if points_pred else 'N/A',\n",
        "            f'{rebounds_pred:.2f}' if rebounds_pred else 'N/A',\n",
        "            f'{assists_pred:.2f}' if assists_pred else 'N/A'\n",
        "        ]\n",
        "    }\n",
        "    summary_df = pd.DataFrame(summary_data)\n",
        "    display(summary_df)\n",
        "    print(\"\\n Full Player Report Complete!\")\n",
        "\n",
        "#  Example Usage\n",
        "# (Change player names as needed)\n",
        "player_full_report('Stephen', 'Curry', 'Rockets', is_home_game=1)\n"
      ],
      "metadata": {
        "id": "pAhFfgNVlmGZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is a test to check the effectiveness of using Random Forest Regression for the center\n",
        "and linear regression for the spread.\n",
        "Conclusion: The linear regression model is not consistent."
      ],
      "metadata": {
        "id": "8C4e5sLBSmFW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test_full_model_calibration(first_name, last_name, is_home_game=1, stat_name='points', threshold=30, num_recent=20, num_opponent=10, max_tests=200):\n",
        "    \"\"\"\n",
        "    Calibrates the full player+matchup prediction model across many games (dynamic opponent detection).\n",
        "    \"\"\"\n",
        "    print(f\"\\n Running full calibration for {first_name} {last_name} (Dynamic Opponent)...\")\n",
        "\n",
        "    # Ensure dates are correct\n",
        "    if not np.issubdtype(player_stats['gameDate'].dtype, np.datetime64):\n",
        "        player_stats['gameDate'] = pd.to_datetime(player_stats['gameDate'])\n",
        "\n",
        "    filtered_stats = player_stats[player_stats['numMinutes'] >= 10]\n",
        "\n",
        "    all_games = filtered_stats[\n",
        "        (filtered_stats['firstName'] == first_name) &\n",
        "        (filtered_stats['lastName'] == last_name)\n",
        "    ].sort_values('gameDate')\n",
        "\n",
        "    if all_games.empty:\n",
        "        print(f\" No data for {first_name} {last_name}.\")\n",
        "        return\n",
        "\n",
        "    predicted_probs = []\n",
        "    actual_results = []\n",
        "\n",
        "    for i in range(num_recent, min(len(all_games), num_recent + max_tests)):\n",
        "        # Progress counter\n",
        "        if (i - num_recent + 1) % 25 == 0:\n",
        "            print(f\" Processed {i - num_recent + 1}/{min(max_tests, len(all_games)-num_recent)} games...\")\n",
        "\n",
        "        past_games = all_games.iloc[i-num_recent:i]\n",
        "        future_game = all_games.iloc[i]\n",
        "\n",
        "        if past_games.empty:\n",
        "            continue\n",
        "\n",
        "        # Detect opponent team dynamically\n",
        "        opponent_team = future_game['opponentteamName']\n",
        "\n",
        "        past_opponent_games = all_games[\n",
        "            (all_games['opponentteamName'] == opponent_team) &\n",
        "            (all_games['gameDate'] < future_game['gameDate'])\n",
        "        ]\n",
        "        recent_opponent_games = past_opponent_games[past_opponent_games['home'] == is_home_game].tail(num_opponent)\n",
        "\n",
        "        recent_games = past_games[past_games['home'] == is_home_game]\n",
        "\n",
        "        if recent_games.empty or recent_opponent_games.empty:\n",
        "            continue\n",
        "\n",
        "        recent_games = drop_highest_and_lowest(recent_games, column=stat_name)\n",
        "        recent_opponent_games = drop_highest_and_lowest(recent_opponent_games, column=stat_name)\n",
        "\n",
        "        if len(recent_games) < 5 or len(recent_opponent_games) < 3:\n",
        "            continue\n",
        "\n",
        "        # Prepare data\n",
        "        recent_games = recent_games.reset_index(drop=True)\n",
        "        recent_games['gameNumber'] = np.arange(len(recent_games))\n",
        "        X_recent = recent_games[['gameNumber']]\n",
        "        y_recent = recent_games[stat_name]\n",
        "\n",
        "        recent_opponent_games = recent_opponent_games.reset_index(drop=True)\n",
        "        recent_opponent_games['gameNumber'] = np.arange(len(recent_opponent_games))\n",
        "        X_opponent = recent_opponent_games[['gameNumber']]\n",
        "        y_opponent = recent_opponent_games[stat_name]\n",
        "\n",
        "        # Random Forest Models\n",
        "        model_recent_rf = RandomForestRegressor(max_depth=3, random_state=42)\n",
        "        model_recent_rf.fit(X_recent, y_recent)\n",
        "\n",
        "        model_opponent_rf = RandomForestRegressor(max_depth=3, random_state=42)\n",
        "        model_opponent_rf.fit(X_opponent, y_opponent)\n",
        "\n",
        "        pred_recent = model_recent_rf.predict(np.array([[len(recent_games)]]))[0]\n",
        "        pred_opponent = model_opponent_rf.predict(np.array([[len(recent_opponent_games)]]))[0]\n",
        "        final_pred = 0.6 * pred_recent + 0.4 * pred_opponent\n",
        "\n",
        "        # Linear Regression for Spread\n",
        "        model_recent_lr = LinearRegression()\n",
        "        model_recent_lr.fit(X_recent, y_recent)\n",
        "\n",
        "        model_opponent_lr = LinearRegression()\n",
        "        model_opponent_lr.fit(X_opponent, y_opponent)\n",
        "\n",
        "        y_recent_pred = model_recent_lr.predict(X_recent)\n",
        "        y_opponent_pred = model_opponent_lr.predict(X_opponent)\n",
        "\n",
        "        ss_recent_res = np.sum((y_recent - y_recent_pred)**2)\n",
        "        ss_recent_tot = np.sum((y_recent - np.mean(y_recent))**2)\n",
        "        r2_recent = 1 - ss_recent_res/ss_recent_tot\n",
        "\n",
        "        ss_opponent_res = np.sum((y_opponent - y_opponent_pred)**2)\n",
        "        ss_opponent_tot = np.sum((y_opponent - np.mean(y_opponent))**2)\n",
        "        r2_opponent = 1 - ss_opponent_res/ss_opponent_tot\n",
        "\n",
        "        avg_r2 = (r2_recent + r2_opponent) / 2\n",
        "        base_std_dev = np.std(np.concatenate([y_recent, y_opponent]))\n",
        "        adj_std_dev = base_std_dev * (1 - avg_r2)\n",
        "        adj_std_dev = max(adj_std_dev, 1)\n",
        "\n",
        "        # Predict probability of exceeding threshold\n",
        "        prob = 1 - norm.cdf(threshold, final_pred, adj_std_dev)\n",
        "        prob = min(prob, 0.99)\n",
        "\n",
        "        predicted_probs.append(prob)\n",
        "        actual_results.append(1 if future_game[stat_name] > threshold else 0)\n",
        "\n",
        "    #Calibration Results\n",
        "    if len(predicted_probs) == 0:\n",
        "        print(\" No games qualified for calibration.\")\n",
        "        return\n",
        "\n",
        "    predicted_probs = np.array(predicted_probs)\n",
        "    actual_results = np.array(actual_results)\n",
        "\n",
        "    bins = np.linspace(0, 1, 21)  # 5% bins\n",
        "    bin_indices = np.digitize(predicted_probs, bins) - 1\n",
        "\n",
        "    bin_true_success = np.zeros(len(bins)-1)\n",
        "    bin_total_counts = np.zeros(len(bins)-1)\n",
        "\n",
        "    for idx, actual in zip(bin_indices, actual_results):\n",
        "        if 0 <= idx < len(bin_true_success):\n",
        "            bin_true_success[idx] += actual\n",
        "            bin_total_counts[idx] += 1\n",
        "\n",
        "    observed_success_rate = np.divide(bin_true_success, bin_total_counts, out=np.zeros_like(bin_true_success), where=bin_total_counts!=0)\n",
        "    bin_midpoints = (bins[:-1] + bins[1:]) / 2\n",
        "\n",
        "    #Plot\n",
        "    fig, ax = plt.subplots(figsize=(10,6))\n",
        "    ax.plot(bin_midpoints, observed_success_rate, marker='o', linestyle='-', color='blue', label='Observed Success')\n",
        "    ax.plot([0,1], [0,1], linestyle='--', color='gray', label='Perfect Calibration')\n",
        "\n",
        "    for i, (mid, count) in enumerate(zip(bin_midpoints, bin_total_counts)):\n",
        "        if count > 0:\n",
        "            ax.annotate(f'n={int(count)}', (mid, observed_success_rate[i]+0.03),\n",
        "                        ha='center', fontsize=8, color='black')\n",
        "\n",
        "    ax.set_xlim(0,1)\n",
        "    ax.set_ylim(0,1)\n",
        "    ax.set_xlabel('Predicted Probability')\n",
        "    ax.set_ylabel('Observed Success Rate')\n",
        "    ax.set_title(f'Calibration Curve: {first_name} {last_name} ({stat_name.capitalize()})')\n",
        "    ax.legend()\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "    # Print Calibration Table\n",
        "    print(\"\\n Calibration Table:\")\n",
        "    for i in range(len(observed_success_rate)):\n",
        "        if bin_total_counts[i] > 0:\n",
        "            print(f\"Bin {bins[i]:.2f}-{bins[i+1]:.2f}: Predicted Avg: {(bins[i]+bins[i+1])/2:.2f}, Observed Success Rate: {observed_success_rate[i]:.2f} (n={int(bin_total_counts[i])})\")\n",
        "\n",
        "    #Print Brier Score\n",
        "    from sklearn.metrics import brier_score_loss\n",
        "    brier = brier_score_loss(actual_results, predicted_probs)\n",
        "    print(f\"\\n Brier Score: {brier:.4f}\")\n",
        "\n",
        "\n",
        "test_full_model_calibration('LeBron', 'James', is_home_game=1, stat_name='points', threshold=30, max_tests=500)\n"
      ],
      "metadata": {
        "id": "vqupyTqllmIp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This model uses Random Forest Regression for the center, and a blend of\n",
        "Linear Regression and Random Forest residuals for the spread.\n",
        "The idea was that the Linear Regression spread was too wide, and the\n",
        "Random Forest spread was too tight, so splitting the difference\n",
        "could fix the issue."
      ],
      "metadata": {
        "id": "CeMEzu67SqZI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_stat_distribution_core(stat_name, first_name, last_name, opponent_team, is_home_game):\n",
        "    \"\"\"\n",
        "    Silent core model: returns final_pred (mean) and adj_std_dev (spread).\n",
        "    \"\"\"\n",
        "    if not np.issubdtype(player_stats['gameDate'].dtype, np.datetime64):\n",
        "        player_stats['gameDate'] = pd.to_datetime(player_stats['gameDate'])\n",
        "\n",
        "    filtered_stats = player_stats[player_stats['numMinutes'] >= 10]\n",
        "    all_games = filtered_stats[\n",
        "        (filtered_stats['firstName'] == first_name) &\n",
        "        (filtered_stats['lastName'] == last_name)\n",
        "    ].sort_values('gameDate')\n",
        "\n",
        "    opponent_games = all_games[all_games['opponentteamName'] == opponent_team]\n",
        "\n",
        "    if all_games.empty or opponent_games.empty:\n",
        "        return None, None\n",
        "\n",
        "    recent_games = all_games[all_games['home'] == is_home_game].tail(20)\n",
        "    recent_opponent_games = opponent_games[opponent_games['home'] == is_home_game].tail(10)\n",
        "\n",
        "    if recent_games.empty or recent_opponent_games.empty:\n",
        "        return None, None\n",
        "\n",
        "    recent_games = drop_highest_and_lowest(recent_games, column=stat_name)\n",
        "    recent_opponent_games = drop_highest_and_lowest(recent_opponent_games, column=stat_name)\n",
        "\n",
        "    if len(recent_games) < 5 or len(recent_opponent_games) < 3:\n",
        "        return None, None\n",
        "\n",
        "    # Recent\n",
        "    recent_games = recent_games.reset_index(drop=True)\n",
        "    recent_games['gameNumber'] = np.arange(len(recent_games))\n",
        "    X_recent = recent_games[['gameNumber']]\n",
        "    y_recent = recent_games[stat_name]\n",
        "\n",
        "    # Matchup\n",
        "    recent_opponent_games = recent_opponent_games.reset_index(drop=True)\n",
        "    recent_opponent_games['gameNumber'] = np.arange(len(recent_opponent_games))\n",
        "    X_opponent = recent_opponent_games[['gameNumber']]\n",
        "    y_opponent = recent_opponent_games[stat_name]\n",
        "\n",
        "    # Random Forest - Center\n",
        "    model_recent_rf = RandomForestRegressor(max_depth=3, random_state=42)\n",
        "    model_recent_rf.fit(X_recent, y_recent)\n",
        "\n",
        "    model_opponent_rf = RandomForestRegressor(max_depth=3, random_state=42)\n",
        "    model_opponent_rf.fit(X_opponent, y_opponent)\n",
        "\n",
        "    pred_recent = model_recent_rf.predict(np.array([[len(recent_games)]]))[0]\n",
        "    pred_opponent = model_opponent_rf.predict(np.array([[len(recent_opponent_games)]]))[0]\n",
        "    final_pred = 0.6 * pred_recent + 0.4 * pred_opponent\n",
        "\n",
        "    # Linear Model - Spread\n",
        "    model_recent_lr = LinearRegression()\n",
        "    model_recent_lr.fit(X_recent, y_recent)\n",
        "\n",
        "    model_opponent_lr = LinearRegression()\n",
        "    model_opponent_lr.fit(X_opponent, y_opponent)\n",
        "\n",
        "    y_recent_pred_lr = model_recent_lr.predict(X_recent)\n",
        "    y_opponent_pred_lr = model_opponent_lr.predict(X_opponent)\n",
        "\n",
        "    ss_recent_lr = np.sum((y_recent - y_recent_pred_lr)**2)\n",
        "    ss_opponent_lr = np.sum((y_opponent - y_opponent_pred_lr)**2)\n",
        "\n",
        "    ss_recent_tot = np.sum((y_recent - np.mean(y_recent))**2)\n",
        "    ss_opponent_tot = np.sum((y_opponent - np.mean(y_opponent))**2)\n",
        "\n",
        "    r2_recent_lr = 1 - ss_recent_lr / ss_recent_tot\n",
        "    r2_opponent_lr = 1 - ss_opponent_lr / ss_opponent_tot\n",
        "\n",
        "    avg_r2_lr = (r2_recent_lr + r2_opponent_lr) / 2\n",
        "\n",
        "    # Random Forest residuals (extra spread)\n",
        "    y_recent_pred_rf = model_recent_rf.predict(X_recent)\n",
        "    y_opponent_pred_rf = model_opponent_rf.predict(X_opponent)\n",
        "\n",
        "    rf_residual_std = np.std(np.concatenate([\n",
        "        y_recent - y_recent_pred_rf,\n",
        "        y_opponent - y_opponent_pred_rf\n",
        "    ]))\n",
        "\n",
        "    # Base std dev\n",
        "    base_std_dev = np.std(np.concatenate([y_recent, y_opponent]))\n",
        "\n",
        "    # Blend spread (50% Linear R² adjustment, 50% Random Forest residual spread)\n",
        "    spread_from_lr = base_std_dev * (1 - avg_r2_lr)\n",
        "    blended_spread = 0.5 * spread_from_lr + 0.5 * rf_residual_std\n",
        "    blended_spread = max(blended_spread, 1)  # minimum noise level\n",
        "\n",
        "    return final_pred, blended_spread\n",
        "\n",
        "def predict_stat_distribution(stat_name, first_name, last_name, opponent_team, is_home_game):\n",
        "    \"\"\"\n",
        "    Full visual function: calls core, then plots, sliders, etc.\n",
        "    \"\"\"\n",
        "    final_pred, adj_std_dev = predict_stat_distribution_core(stat_name, first_name, last_name, opponent_team, is_home_game)\n",
        "\n",
        "    if final_pred is None or adj_std_dev is None:\n",
        "        print(\"Not enough data to predict.\")\n",
        "        return None, None\n",
        "\n",
        "    # Bell curve plotting\n",
        "    x = np.linspace(final_pred - 3*adj_std_dev, final_pred + 3*adj_std_dev, 500)\n",
        "    y = norm.pdf(x, final_pred, adj_std_dev)\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(8,6))\n",
        "    ax.plot(x, y)\n",
        "    ax.fill_between(x, y, alpha=0.5)\n",
        "    ax.axvline(final_pred, color='red', linestyle='--', label=f'Predicted {stat_name}: {final_pred:.2f}')\n",
        "\n",
        "    thresholds = []\n",
        "    if final_pred <= 10:\n",
        "        thresholds = [int(final_pred - 4), int(final_pred - 2), int(final_pred), int(final_pred + 2), int(final_pred + 4)]\n",
        "    elif final_pred <= 20:\n",
        "        thresholds = [int(final_pred - 6), int(final_pred - 3), int(final_pred), int(final_pred + 3), int(final_pred + 6)]\n",
        "    else:\n",
        "        thresholds = [int(final_pred - 10), int(final_pred - 5), int(final_pred), int(final_pred + 5), int(final_pred + 10)]\n",
        "    thresholds = [thresh for thresh in thresholds if thresh > 0]\n",
        "\n",
        "    for thresh in thresholds:\n",
        "        y_thresh = norm.pdf(thresh, final_pred, adj_std_dev)\n",
        "        prob = min((1 - norm.cdf(thresh, final_pred, adj_std_dev)) * 100, 99)\n",
        "        ax.scatter(thresh, y_thresh, color='black')\n",
        "        ax.text(thresh, y_thresh + max(y)*0.03, f'{thresh} ({prob:.0f}%)', ha='center', fontsize=9, color='black')\n",
        "\n",
        "    ax.set_title(f'Predicted {stat_name.capitalize()} Distribution (RF Center + Mixed Spread)')\n",
        "    ax.set_xlabel(f'{stat_name.capitalize()}')\n",
        "    ax.set_ylabel('Probability Density')\n",
        "    ax.legend()\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "    # Interactive Probability Slider\n",
        "    print(f\"\\n Interactive Probability Slider for {stat_name.capitalize()}:\")\n",
        "    slider = widgets.IntSlider(\n",
        "        value=int(final_pred),\n",
        "        min=int(final_pred - 10),\n",
        "        max=int(final_pred + 20),\n",
        "        step=1,\n",
        "        description=f'{stat_name}',\n",
        "        continuous_update=False\n",
        "    )\n",
        "    def calculate_probability(threshold):\n",
        "        prob = 1 - norm.cdf(threshold, final_pred, adj_std_dev)\n",
        "        prob = min(prob, 0.99)\n",
        "        print(f\" Probability of more than {threshold} {stat_name}: {prob*100:.2f}%\")\n",
        "    output = widgets.interactive_output(calculate_probability, {'threshold': slider})\n",
        "    display(slider, output)\n",
        "\n",
        "    return final_pred, adj_std_dev\n",
        "\n",
        "\n",
        "predict_stat_distribution('points', 'Stephen', 'Curry', 'Rockets', is_home_game=1)\n"
      ],
      "metadata": {
        "id": "Qv4L6DGiqoZM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This model tests the previous model across multiple players over time.\n",
        "Conclusion: The model becomes very overconfident at higher values."
      ],
      "metadata": {
        "id": "YzT5IVLTR58M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test_full_model_calibration_multiple_players(player_list, is_home_game=1, stat_name='points', threshold=30, num_recent=20, num_opponent=10, max_tests=200):\n",
        "    \"\"\"\n",
        "    Calibrates model across multiple players.\n",
        "    \"\"\"\n",
        "    print(f\"\\n Running full calibration across {len(player_list)} players...\")\n",
        "\n",
        "    predicted_probs = []\n",
        "    actual_results = []\n",
        "\n",
        "    for first_name, last_name in player_list:\n",
        "        print(f\"\\n Calibrating {first_name} {last_name}...\")\n",
        "\n",
        "        if not np.issubdtype(player_stats['gameDate'].dtype, np.datetime64):\n",
        "            player_stats['gameDate'] = pd.to_datetime(player_stats['gameDate'])\n",
        "\n",
        "        filtered_stats = player_stats[player_stats['numMinutes'] >= 10]\n",
        "\n",
        "        all_games = filtered_stats[\n",
        "            (filtered_stats['firstName'] == first_name) &\n",
        "            (filtered_stats['lastName'] == last_name)\n",
        "        ].sort_values('gameDate')\n",
        "\n",
        "        if all_games.empty:\n",
        "            print(f\"No games found for {first_name} {last_name}. Skipping...\")\n",
        "            continue\n",
        "\n",
        "        for i in range(num_recent, min(len(all_games), num_recent + max_tests)):\n",
        "            past_games = all_games.iloc[i-num_recent:i]\n",
        "            future_game = all_games.iloc[i]\n",
        "\n",
        "            if past_games.empty:\n",
        "                continue\n",
        "\n",
        "            opponent_team = future_game['opponentteamName']\n",
        "\n",
        "            final_pred, adj_std_dev = predict_stat_distribution_core(stat_name, first_name, last_name, opponent_team, is_home_game)\n",
        "\n",
        "            if final_pred is None or adj_std_dev is None:\n",
        "                continue\n",
        "\n",
        "            prob = 1 - norm.cdf(threshold, final_pred, adj_std_dev)\n",
        "            prob = min(prob, 0.99)\n",
        "\n",
        "            predicted_probs.append(prob)\n",
        "            actual_results.append(1 if future_game[stat_name] > threshold else 0)\n",
        "\n",
        "    # Calibration Results\n",
        "    if len(predicted_probs) == 0:\n",
        "        print(\" No games qualified for calibration.\")\n",
        "        return\n",
        "\n",
        "    predicted_probs = np.array(predicted_probs)\n",
        "    actual_results = np.array(actual_results)\n",
        "\n",
        "    bins = np.linspace(0, 1, 21)\n",
        "    bin_indices = np.digitize(predicted_probs, bins) - 1\n",
        "\n",
        "    bin_true_success = np.zeros(len(bins)-1)\n",
        "    bin_total_counts = np.zeros(len(bins)-1)\n",
        "\n",
        "    for idx, actual in zip(bin_indices, actual_results):\n",
        "        if 0 <= idx < len(bin_true_success):\n",
        "            bin_true_success[idx] += actual\n",
        "            bin_total_counts[idx] += 1\n",
        "\n",
        "    observed_success_rate = np.divide(bin_true_success, bin_total_counts, out=np.zeros_like(bin_true_success), where=bin_total_counts!=0)\n",
        "    bin_midpoints = (bins[:-1] + bins[1:]) / 2\n",
        "\n",
        "    #Plot\n",
        "    fig, ax = plt.subplots(figsize=(10,6))\n",
        "    ax.plot(bin_midpoints, observed_success_rate, marker='o', linestyle='-', color='blue', label='Observed Success')\n",
        "    ax.plot([0,1], [0,1], linestyle='--', color='gray', label='Perfect Calibration')\n",
        "\n",
        "    for i, (mid, count) in enumerate(zip(bin_midpoints, bin_total_counts)):\n",
        "        if count > 0:\n",
        "            ax.annotate(f'n={int(count)}', (mid, observed_success_rate[i]+0.03),\n",
        "                        ha='center', fontsize=8, color='black')\n",
        "\n",
        "    ax.set_xlim(0,1)\n",
        "    ax.set_ylim(0,1)\n",
        "    ax.set_xlabel('Predicted Probability')\n",
        "    ax.set_ylabel('Observed Success Rate')\n",
        "    ax.set_title(f'Calibration Curve: Multiple Players ({stat_name.capitalize()})')\n",
        "    ax.legend()\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "    #Print Calibration Table\n",
        "    print(\"\\n Calibration Table:\")\n",
        "    for i in range(len(observed_success_rate)):\n",
        "        if bin_total_counts[i] > 0:\n",
        "            print(f\"Bin {bins[i]:.2f}-{bins[i+1]:.2f}: Predicted Avg: {(bins[i]+bins[i+1])/2:.2f}, Observed Success Rate: {observed_success_rate[i]:.2f} (n={int(bin_total_counts[i])})\")\n",
        "\n",
        "    #Brier Score\n",
        "    from sklearn.metrics import brier_score_loss\n",
        "    brier = brier_score_loss(actual_results, predicted_probs)\n",
        "    print(f\"\\n Brier Score: {brier:.4f}\")\n",
        "\n",
        "\n",
        "players = [\n",
        "    ('LeBron', 'James'),\n",
        "    ('Stephen', 'Curry'),\n",
        "    ('Jarred', 'Vanderbilt'),\n",
        "    ('Mike', 'Conley'),\n",
        "    ('Naz', 'Reid'),\n",
        "    ('Derrick', 'White'),\n",
        "    ('Dorian', 'Finney-Smith'),\n",
        "    ('Sam', 'Hauser'),\n",
        "    ('Rui', 'Hacchimura'),\n",
        "    ('Rudy', 'Gobert')\n",
        "]\n",
        "\n",
        "test_full_model_calibration_multiple_players(players, is_home_game=1, stat_name='points', threshold=15, max_tests=100)\n",
        "\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "SJbQ_iPF-lpx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This model uses Kernel Density Estimation for the player prediction. This will result in a more dynamic spread, as human players cannot be simplified into a normal distribution curve.\n",
        "Conclusion: The spread seems more realistic, but the center prediction isn't accurate."
      ],
      "metadata": {
        "id": "SwNyty1SS8Bc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#KDE\n",
        "def predict_stat_distribution_core(stat_name, first_name, last_name, opponent_team, is_home_game):\n",
        "    \"\"\"\n",
        "    Silent core model: returns final predicted KDE object based on real past data.\n",
        "    \"\"\"\n",
        "    if not np.issubdtype(player_stats['gameDate'].dtype, np.datetime64):\n",
        "        player_stats['gameDate'] = pd.to_datetime(player_stats['gameDate'])\n",
        "\n",
        "    filtered_stats = player_stats[player_stats['numMinutes'] >= 10]\n",
        "    all_games = filtered_stats[\n",
        "        (filtered_stats['firstName'] == first_name) &\n",
        "        (filtered_stats['lastName'] == last_name)\n",
        "    ].sort_values('gameDate')\n",
        "\n",
        "    opponent_games = all_games[all_games['opponentteamName'] == opponent_team]\n",
        "\n",
        "    if all_games.empty or opponent_games.empty:\n",
        "        return None, None\n",
        "\n",
        "    recent_games = all_games[all_games['home'] == is_home_game].tail(20)\n",
        "    recent_opponent_games = opponent_games[opponent_games['home'] == is_home_game].tail(10)\n",
        "\n",
        "    if recent_games.empty or recent_opponent_games.empty:\n",
        "        return None, None\n",
        "\n",
        "    recent_games = drop_highest_and_lowest(recent_games, column=stat_name)\n",
        "    recent_opponent_games = drop_highest_and_lowest(recent_opponent_games, column=stat_name)\n",
        "\n",
        "    if len(recent_games) < 5 or len(recent_opponent_games) < 3:\n",
        "        return None, None\n",
        "\n",
        "    y_recent = recent_games[stat_name]\n",
        "    y_opponent = recent_opponent_games[stat_name]\n",
        "\n",
        "    # Final combined data for KDE\n",
        "    combined_data = np.concatenate([y_recent, y_opponent])\n",
        "\n",
        "    # Build KDE from actual past stat values\n",
        "    kde = gaussian_kde(combined_data, bw_method='scott')  # 'scott' is good general smoothing\n",
        "\n",
        "    return kde, combined_data\n",
        "\n",
        "\n",
        "def predict_stat_distribution(stat_name, first_name, last_name, opponent_team, is_home_game):\n",
        "    \"\"\"\n",
        "    Full visual version: builds KDE curve, shows probability sliders and plots.\n",
        "    \"\"\"\n",
        "    kde, combined_data = predict_stat_distribution_core(stat_name, first_name, last_name, opponent_team, is_home_game)\n",
        "\n",
        "    if kde is None or combined_data is None:\n",
        "        print(\"Not enough data to predict.\")\n",
        "        return None, None\n",
        "\n",
        "    final_pred = np.mean(combined_data)  # Estimated \"average\" stat performance\n",
        "\n",
        "    # Create x axis points\n",
        "    x_min = min(combined_data) - 5\n",
        "    x_max = max(combined_data) + 5\n",
        "    x = np.linspace(x_min, x_max, 500)\n",
        "    y = kde(x)\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(8,6))\n",
        "    ax.plot(x, y)\n",
        "    ax.fill_between(x, y, alpha=0.5)\n",
        "    ax.axvline(final_pred, color='red', linestyle='--', label=f'Predicted Mean {stat_name}: {final_pred:.2f}')\n",
        "\n",
        "    thresholds = []\n",
        "    if final_pred <= 10:\n",
        "        thresholds = [int(final_pred - 4), int(final_pred - 2), int(final_pred), int(final_pred + 2), int(final_pred + 4)]\n",
        "    elif final_pred <= 20:\n",
        "        thresholds = [int(final_pred - 6), int(final_pred - 3), int(final_pred), int(final_pred + 3), int(final_pred + 6)]\n",
        "    else:\n",
        "        thresholds = [int(final_pred - 10), int(final_pred - 5), int(final_pred), int(final_pred + 5), int(final_pred + 10)]\n",
        "    thresholds = [thresh for thresh in thresholds if thresh > 0]\n",
        "\n",
        "    for thresh in thresholds:\n",
        "        # Integrate KDE from threshold to +inf\n",
        "        mask = x >= thresh\n",
        "        prob = np.trapz(y[mask], x[mask])\n",
        "        prob = min(prob, 0.99)\n",
        "\n",
        "        y_thresh = kde(thresh)[0]\n",
        "        ax.scatter(thresh, y_thresh, color='black')\n",
        "        ax.text(thresh, y_thresh + max(y)*0.03, f'{thresh} ({prob*100:.0f}%)', ha='center', fontsize=9, color='black')\n",
        "\n",
        "    ax.set_title(f'Predicted {stat_name.capitalize()} Distribution (KDE-Based)')\n",
        "    ax.set_xlabel(f'{stat_name.capitalize()}')\n",
        "    ax.set_ylabel('Probability Density')\n",
        "    ax.legend()\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "    #Interactive slider\n",
        "    print(f\"\\n Interactive Probability Slider for {stat_name.capitalize()}:\")\n",
        "    slider = widgets.IntSlider(\n",
        "        value=int(final_pred),\n",
        "        min=int(x_min),\n",
        "        max=int(x_max),\n",
        "        step=1,\n",
        "        description=f'{stat_name}',\n",
        "        continuous_update=False\n",
        "    )\n",
        "\n",
        "    def calculate_probability(threshold):\n",
        "        mask = x >= threshold\n",
        "        prob = np.trapz(y[mask], x[mask])\n",
        "        prob = min(prob, 0.99)\n",
        "        print(f\"Probability of more than {threshold} {stat_name}: {prob*100:.2f}%\")\n",
        "\n",
        "    output = widgets.interactive_output(calculate_probability, {'threshold': slider})\n",
        "    display(slider, output)\n",
        "\n",
        "    return final_pred, kde\n",
        "\n",
        "predict_stat_distribution('points', 'Stephen', 'Curry', 'Rockets', is_home_game=1)\n"
      ],
      "metadata": {
        "id": "ONWI4q7D-lsF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This model uses the most accurate center predictor, Random Forest Regression, along with the most realistic spread generator, which is Kernel Density Estimation."
      ],
      "metadata": {
        "id": "Af0XGo3ITZ-g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#RF center KDE spread\n",
        "def predict_stat_distribution_core(stat_name, first_name, last_name, opponent_team, is_home_game):\n",
        "    \"\"\"\n",
        "    Silent core model: predicts center with Random Forest, models spread with shifted KDE.\n",
        "    \"\"\"\n",
        "    if not np.issubdtype(player_stats['gameDate'].dtype, np.datetime64):\n",
        "        player_stats['gameDate'] = pd.to_datetime(player_stats['gameDate'])\n",
        "\n",
        "    filtered_stats = player_stats[player_stats['numMinutes'] >= 10]\n",
        "    all_games = filtered_stats[\n",
        "        (filtered_stats['firstName'] == first_name) &\n",
        "        (filtered_stats['lastName'] == last_name)\n",
        "    ].sort_values('gameDate')\n",
        "\n",
        "    opponent_games = all_games[all_games['opponentteamName'] == opponent_team]\n",
        "\n",
        "    if all_games.empty or opponent_games.empty:\n",
        "        return None, None, None\n",
        "\n",
        "    recent_games = all_games[all_games['home'] == is_home_game].tail(20)\n",
        "    recent_opponent_games = opponent_games[opponent_games['home'] == is_home_game].tail(10)\n",
        "\n",
        "    if recent_games.empty or recent_opponent_games.empty:\n",
        "        return None, None, None\n",
        "\n",
        "    recent_games = drop_highest_and_lowest(recent_games, column=stat_name)\n",
        "    recent_opponent_games = drop_highest_and_lowest(recent_opponent_games, column=stat_name)\n",
        "\n",
        "    if len(recent_games) < 5 or len(recent_opponent_games) < 3:\n",
        "        return None, None, None\n",
        "\n",
        "    recent_games = recent_games.reset_index(drop=True)\n",
        "    recent_games['gameNumber'] = np.arange(len(recent_games))\n",
        "\n",
        "    recent_opponent_games = recent_opponent_games.reset_index(drop=True)\n",
        "    recent_opponent_games['gameNumber'] = np.arange(len(recent_opponent_games))\n",
        "\n",
        "    X_recent = recent_games[['gameNumber']]\n",
        "    y_recent = recent_games[stat_name]\n",
        "\n",
        "    X_opponent = recent_opponent_games[['gameNumber']]\n",
        "    y_opponent = recent_opponent_games[stat_name]\n",
        "\n",
        "    #Train Random Forest for center prediction\n",
        "    model_recent_rf = RandomForestRegressor(max_depth=5, n_estimators=100, random_state=42)\n",
        "    model_recent_rf.fit(X_recent, y_recent)\n",
        "\n",
        "    model_opponent_rf = RandomForestRegressor(max_depth=5, n_estimators=100, random_state=42)\n",
        "    model_opponent_rf.fit(X_opponent, y_opponent)\n",
        "\n",
        "    pred_recent = model_recent_rf.predict([[len(X_recent)]])[0]\n",
        "    pred_opponent = model_opponent_rf.predict([[len(X_opponent)]])[0]\n",
        "\n",
        "    final_pred = 0.6 * pred_recent + 0.4 * pred_opponent\n",
        "\n",
        "    #Build KDE from real past stats\n",
        "    combined_data = np.concatenate([y_recent, y_opponent])\n",
        "    kde_original = gaussian_kde(combined_data, bw_method='scott')\n",
        "\n",
        "    #Shift KDE so that its mean matches RF predicted center\n",
        "    original_mean = np.mean(combined_data)\n",
        "    shift_amount = final_pred - original_mean\n",
        "\n",
        "    def shifted_kde(x):\n",
        "        return kde_original(x - shift_amount)\n",
        "\n",
        "    return final_pred, shifted_kde, (min(combined_data), max(combined_data))\n",
        "\n",
        "\n",
        "def predict_stat_distribution(stat_name, first_name, last_name, opponent_team, is_home_game):\n",
        "    \"\"\"\n",
        "    Full visual version: uses Random Forest for center, KDE for spread.\n",
        "    \"\"\"\n",
        "    final_pred, shifted_kde, (data_min, data_max) = predict_stat_distribution_core(stat_name, first_name, last_name, opponent_team, is_home_game)\n",
        "\n",
        "    if final_pred is None or shifted_kde is None:\n",
        "        print(\"Not enough data to predict.\")\n",
        "        return None, None\n",
        "\n",
        "    # Create x axis points\n",
        "    x_min = data_min - 10\n",
        "    x_max = data_max + 10\n",
        "    x = np.linspace(x_min, x_max, 500)\n",
        "    y = shifted_kde(x)\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(8,6))\n",
        "    ax.plot(x, y)\n",
        "    ax.fill_between(x, y, alpha=0.5)\n",
        "    ax.axvline(final_pred, color='red', linestyle='--', label=f'Predicted Center {stat_name}: {final_pred:.2f}')\n",
        "\n",
        "    thresholds = []\n",
        "    if final_pred <= 10:\n",
        "        thresholds = [int(final_pred - 4), int(final_pred - 2), int(final_pred), int(final_pred + 2), int(final_pred + 4)]\n",
        "    elif final_pred <= 20:\n",
        "        thresholds = [int(final_pred - 6), int(final_pred - 3), int(final_pred), int(final_pred + 3), int(final_pred + 6)]\n",
        "    else:\n",
        "        thresholds = [int(final_pred - 10), int(final_pred - 5), int(final_pred), int(final_pred + 5), int(final_pred + 10)]\n",
        "    thresholds = [thresh for thresh in thresholds if thresh > 0]\n",
        "\n",
        "    for thresh in thresholds:\n",
        "        mask = x >= thresh\n",
        "        prob = np.trapz(y[mask], x[mask])\n",
        "        prob = min(prob, 0.99)\n",
        "\n",
        "        y_thresh = shifted_kde(thresh)[0]\n",
        "        ax.scatter(thresh, y_thresh, color='black')\n",
        "        ax.text(thresh, y_thresh + max(y)*0.03, f'{thresh} ({prob*100:.0f}%)', ha='center', fontsize=9, color='black')\n",
        "\n",
        "    ax.set_title(f'Predicted {stat_name.capitalize()} Distribution (RF Center + KDE Spread)')\n",
        "    ax.set_xlabel(f'{stat_name.capitalize()}')\n",
        "    ax.set_ylabel('Probability Density')\n",
        "    ax.legend()\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "    #Interactive slider\n",
        "    print(f\"\\nInteractive Probability Slider for {stat_name.capitalize()}:\")\n",
        "    slider = widgets.IntSlider(\n",
        "        value=int(final_pred),\n",
        "        min=int(x_min),\n",
        "        max=int(x_max),\n",
        "        step=1,\n",
        "        description=f'{stat_name}',\n",
        "        continuous_update=False\n",
        "    )\n",
        "\n",
        "    def calculate_probability(threshold):\n",
        "        mask = x >= threshold\n",
        "        prob = np.trapz(y[mask], x[mask])\n",
        "        prob = min(prob, 0.99)\n",
        "        print(f\"Probability of more than {threshold} {stat_name}: {prob*100:.2f}%\")\n",
        "\n",
        "    output = widgets.interactive_output(calculate_probability, {'threshold': slider})\n",
        "    display(slider, output)\n",
        "\n",
        "    return final_pred, shifted_kde\n",
        "\n",
        "predict_stat_distribution('points', 'Stephen', 'Curry', 'Rockets', is_home_game=1)\n"
      ],
      "metadata": {
        "id": "qiw8fbUt-luR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This test checks the effectiveness of using Random Forest Regression for the center prediction and using Kernel Density Estimation for the spread.\n",
        "Conclusion: While the model is still overconfident at higher values, it is much more accurate than previous models."
      ],
      "metadata": {
        "id": "OYTHDWXLTv6e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#test\n",
        "def test_full_model_calibration_multiple_players(player_list, is_home_game=1, stat_name='points', threshold=30, num_recent=20, max_tests=200):\n",
        "    \"\"\"\n",
        "    Calibrates the full RF+KDE hybrid model across multiple players.\n",
        "    \"\"\"\n",
        "    print(f\"\\nRunning full calibration across {len(player_list)} players...\")\n",
        "\n",
        "    predicted_probs = []\n",
        "    actual_results = []\n",
        "\n",
        "    for first_name, last_name in player_list:\n",
        "        print(f\"\\nCalibrating {first_name} {last_name}...\")\n",
        "\n",
        "        if not np.issubdtype(player_stats['gameDate'].dtype, np.datetime64):\n",
        "            player_stats['gameDate'] = pd.to_datetime(player_stats['gameDate'])\n",
        "\n",
        "        filtered_stats = player_stats[player_stats['numMinutes'] >= 10]\n",
        "\n",
        "        all_games = filtered_stats[\n",
        "            (filtered_stats['firstName'] == first_name) &\n",
        "            (filtered_stats['lastName'] == last_name)\n",
        "        ].sort_values('gameDate')\n",
        "\n",
        "        if all_games.empty:\n",
        "            print(f\"No games found for {first_name} {last_name}. Skipping...\")\n",
        "            continue\n",
        "\n",
        "        for i in range(num_recent, min(len(all_games), num_recent + max_tests)):\n",
        "            past_games = all_games.iloc[i-num_recent:i]\n",
        "            future_game = all_games.iloc[i]\n",
        "\n",
        "            if past_games.empty:\n",
        "                continue\n",
        "\n",
        "            opponent_team = future_game['opponentteamName']\n",
        "\n",
        "            final_pred, shifted_kde, _ = predict_stat_distribution_core(stat_name, first_name, last_name, opponent_team, is_home_game)\n",
        "\n",
        "            if final_pred is None or shifted_kde is None:\n",
        "                continue\n",
        "\n",
        "            # Now calculate probability\n",
        "            x = np.linspace(final_pred - 30, final_pred + 30, 500)\n",
        "            y = shifted_kde(x)\n",
        "\n",
        "            mask = x >= threshold\n",
        "            prob = np.trapz(y[mask], x[mask])\n",
        "            prob = min(prob, 0.99)\n",
        "\n",
        "            predicted_probs.append(prob)\n",
        "            actual_results.append(1 if future_game[stat_name] > threshold else 0)\n",
        "\n",
        "    #Calibration Results\n",
        "    if len(predicted_probs) == 0:\n",
        "        print(\"No games qualified for calibration.\")\n",
        "        return\n",
        "\n",
        "    predicted_probs = np.array(predicted_probs)\n",
        "    actual_results = np.array(actual_results)\n",
        "\n",
        "    bins = np.linspace(0, 1, 21)  # 5% bins\n",
        "    bin_indices = np.digitize(predicted_probs, bins) - 1\n",
        "\n",
        "    bin_true_success = np.zeros(len(bins)-1)\n",
        "    bin_total_counts = np.zeros(len(bins)-1)\n",
        "\n",
        "    for idx, actual in zip(bin_indices, actual_results):\n",
        "        if 0 <= idx < len(bin_true_success):\n",
        "            bin_true_success[idx] += actual\n",
        "            bin_total_counts[idx] += 1\n",
        "\n",
        "    observed_success_rate = np.divide(bin_true_success, bin_total_counts, out=np.zeros_like(bin_true_success), where=bin_total_counts!=0)\n",
        "    bin_midpoints = (bins[:-1] + bins[1:]) / 2\n",
        "\n",
        "    #Plot\n",
        "    fig, ax = plt.subplots(figsize=(10,6))\n",
        "    ax.plot(bin_midpoints, observed_success_rate, marker='o', linestyle='-', color='blue', label='Observed Success')\n",
        "    ax.plot([0,1], [0,1], linestyle='--', color='gray', label='Perfect Calibration')\n",
        "\n",
        "    for i, (mid, count) in enumerate(zip(bin_midpoints, bin_total_counts)):\n",
        "        if count > 0:\n",
        "            ax.annotate(f'n={int(count)}', (mid, observed_success_rate[i]+0.03),\n",
        "                        ha='center', fontsize=8, color='black')\n",
        "\n",
        "    ax.set_xlim(0,1)\n",
        "    ax.set_ylim(0,1)\n",
        "    ax.set_xlabel('Predicted Probability')\n",
        "    ax.set_ylabel('Observed Success Rate')\n",
        "    ax.set_title(f'Calibration Curve: Multiple Players ({stat_name.capitalize()})')\n",
        "    ax.legend()\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "    #Print Calibration Table\n",
        "    print(\"\\nCalibration Table:\")\n",
        "    for i in range(len(observed_success_rate)):\n",
        "        if bin_total_counts[i] > 0:\n",
        "            print(f\"Bin {bins[i]:.2f}-{bins[i+1]:.2f}: Predicted Avg: {(bins[i]+bins[i+1])/2:.2f}, Observed Success Rate: {observed_success_rate[i]:.2f} (n={int(bin_total_counts[i])})\")\n",
        "\n",
        "    #Brier Score\n",
        "    from sklearn.metrics import brier_score_loss\n",
        "    brier = brier_score_loss(actual_results, predicted_probs)\n",
        "    print(f\"\\nBrier Score: {brier:.4f}\")\n",
        "\n",
        "\n",
        "players = [\n",
        "    ('LeBron', 'James'),\n",
        "    ('Stephen', 'Curry'),\n",
        "    ('Jarred', 'Vanderbilt'),\n",
        "    ('Mike', 'Conley'),\n",
        "    ('Naz', 'Reid'),\n",
        "    ('Derrick', 'White'),\n",
        "    ('Dorian', 'Finney-Smith'),\n",
        "    ('Sam', 'Hauser'),\n",
        "    ('Rui', 'Hacchimura'),\n",
        "    ('Rudy', 'Gobert')\n",
        "]\n",
        "\n",
        "test_full_model_calibration_multiple_players(\n",
        "    players,\n",
        "    is_home_game=1,\n",
        "    stat_name='reboundsTotal',\n",
        "    threshold=6,\n",
        "    num_recent=20,\n",
        "    max_tests=200\n",
        ")"
      ],
      "metadata": {
        "id": "Ux51blJPqojr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this project, we successfully predicted NBA player points, rebounds, and assists based on historical game statistics.\n",
        "Using Stephen Curry as an example, the final version of the data used was gathered before Warriors vs. Rockets Game 3 of the 2025 NBA Playoffs Round 1. The model preicted Steph to score 33 points and he ended up scoring 36.\n",
        "Random Forest Regression outperformed Linear Regression in terms of finding the central prediction.\n",
        "Kernel Density Estimation resulted in the most realistic spread.\n",
        "Future improvements would include adding context like trends for the opponent defensive strength, injury reports, as well as specific player tracking data like points from specific spots on the court."
      ],
      "metadata": {
        "id": "1jxDSF-qUDO5"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}